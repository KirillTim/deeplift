{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 4: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5004)\n"
     ]
    }
   ],
   "source": [
    "#Set up environment and import necessary dependencies\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import division;\n",
    "from __future__ import print_function;\n",
    "from __future__ import absolute_import;\n",
    "import sys, os;\n",
    "from collections import OrderedDict, namedtuple, Counter;\n",
    "import numpy as np;\n",
    "import theano\n",
    "np.random.seed(1234)\n",
    "\n",
    "#scriptsDir = os.environ.get(\"KERAS_DIR\");\n",
    "#if (scriptsDir is None):\n",
    "#    raise Exception(\"Please set environment variable KERAS_DIR\");\n",
    "#sys.path.insert(0,scriptsDir)\n",
    "#import keras\n",
    "\n",
    "\n",
    "#Import some general util stuff\n",
    "scriptsDir = os.environ.get(\"UTIL_SCRIPTS_DIR\");\n",
    "if (scriptsDir is None):\n",
    "    raise Exception(\"Please set environment variable UTIL_SCRIPTS_DIR to point to av_scripts\");\n",
    "sys.path.insert(0,scriptsDir);\n",
    "import pathSetter;\n",
    "import util;\n",
    "import fileProcessing as fp\n",
    "from plottingUtilitiesPackage import matplotlibHelpers as mplh;\n",
    "\n",
    "import deeplift\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the keras model, make sure you normalise the weights\n",
    "#of the first convolutional layer to be mean-centered at each position.\n",
    "import vgg16_keras \n",
    "reload(vgg16_keras)\n",
    "from vgg16_keras import *\n",
    "import h5py\n",
    "#path_to_weights_file = '/srv/scratch/annashch/cs231n_project/vgg16_weights_dropout_regularization_augmenteddataTintContrast.stupidsgd.hdf5'\n",
    "\n",
    "#'/srv/scratch/annashch/cs231n_project/hdf5/vgg16_weights_dropout_regularization_augmenteddataTintContrast.stupidsgd.hdf5'\n",
    "#path_to_weights_file = '/srv/scratch/annashch/cs231n_project/best/weights.with.zeros.adam.hdf5'\n",
    "#/srv/scratch/annashch/cs231n_project/pretrained_model.h5'\n",
    "\n",
    "path_to_weights_file = '/srv/scratch/annashch/cs231n_project/hdf5/vgg16_weights_dropout_regularization_augmenteddataTintContrast.stupidsgd.hdf5'\n",
    "#path_to_weights_file = '/srv/scratch/annashch/cs231n_project/hdf5/assignment3_weights_dropout_regularization_augmenteddataTintContrast.stupidsgd.hdf5'\n",
    "\n",
    "#import pretrained\n",
    "#reload(pretrained)\n",
    "#keras_model = pretrained.pretrained_finetune(path_to_weights_file, 0)\n",
    "\n",
    "keras_model=vgg16_keras.VGG_16(path_to_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.ZeroPadding2D at 0x7fb54211bd50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fb54202c750>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fb542034e50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fb54203ec90>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7fb54205f090>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fb54205f210>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fb54209f050>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fb54209fb50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fb542082390>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7fb54208d050>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fb54208d210>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fb5420a8150>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fb5420b6590>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fb5420c23d0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fb5420b6bd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fb5420e1590>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7fb5420e9390>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fb5420e9550>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fb542100510>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fb542006750>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fb542013690>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fb542013190>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fb541faf950>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7fb541fbe890>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fb541fbea50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fb541fca410>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fb541fd6d10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fb541fe5cd0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fb541f72b90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fb541f8f050>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7fb541f8ff50>,\n",
       " <keras.layers.core.Flatten at 0x7fb541f99150>,\n",
       " <keras.layers.core.Dense at 0x7fb541fa6510>,\n",
       " <keras.layers.core.Dropout at 0x7fb541fa6d90>,\n",
       " <keras.layers.core.Dense at 0x7fb541fa6290>,\n",
       " <keras.layers.core.Dropout at 0x7fb53bf49390>,\n",
       " <keras.layers.core.Dense at 0x7fb53bf58790>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import deeplift.conversion.keras_conversion as kc\n",
    "reload(kc)\n",
    "import deeplift.backend as B\n",
    "reload(B)\n",
    "import deeplift.blobs as blobs\n",
    "reload(blobs)\n",
    "import deeplift.models as models\n",
    "reload(models)\n",
    "import deeplift.util as deeplift_util\n",
    "reload(deeplift_util)\n",
    "from deeplift.blobs import MxtsMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kc.mean_normalise_softmax_weights(keras_model.layers[-1])\n",
    "deeplift_model = kc.convert_sequential_model(keras_model, mxts_mode=MxtsMode.DeepLIFT)\n",
    "deeplift_contribs_func = deeplift_model.get_target_contribs_func(find_scores_layer_idx=0)\n",
    "deeplift_multipliers_func = deeplift_model.get_target_multipliers_func(find_scores_layer_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deeplift_expo_upweight_model = kc.convert_sequential_model(keras_model, mxts_mode=MxtsMode.DeepLIFT, expo_upweight_factor=0.08)\n",
    "deeplift_expo_upweight_contribs_func = deeplift_expo_upweight_model.get_target_contribs_func(find_scores_layer_idx=0)\n",
    "#deeplift_expo_upweight_multipliers_func = deeplift_expo_upweight_model.get_target_multipliers_func(find_scores_layer_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "guided_backprop_model = kc.convert_sequential_model(keras_model, mxts_mode=MxtsMode.GuidedBackprop)\n",
    "guided_backprop_multipliers_func = guided_backprop_model.get_target_multipliers_func(find_scores_layer_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "guided_backprop_contribs_func = guided_backprop_model.get_target_contribs_func(find_scores_layer_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gradient_model = kc.convert_sequential_model(keras_model, mxts_mode=MxtsMode.Gradient)\n",
    "gradient_func = gradient_model.get_target_multipliers_func(find_scores_layer_idx=0)\n",
    "grad_times_inp_func = gradient_model.get_target_contribs_func(find_scores_layer_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#deconv_model = kc.convert_sequential_model(keras_model, mxts_mode=MxtsMode.DeconvNet)\n",
    "#deconv_multipliers_func = deconv_model.get_target_multipliers_func(input_layer_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "guided_backprop_deeplift_model = kc.convert_sequential_model(keras_model, mxts_mode=MxtsMode.GuidedBackpropDeepLIFT)\n",
    "guided_backprop_deeplift_contribs_func = guided_backprop_deeplift_model.get_target_contribs_func(find_scores_layer_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "guided_backprop_deeplift_expo_upweight_model = kc.convert_sequential_model(keras_model,\n",
    "                                                                           mxts_mode=MxtsMode.GuidedBackpropDeepLIFT,\n",
    "                                                                           expo_upweight_factor=0.08)\n",
    "guided_backprop_deeplift_expo_upweight_contribs_func = guided_backprop_deeplift_expo_upweight_model.get_target_contribs_func(find_scores_layer_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "path_to_data_file = '/srv/scratch/annashch/tiny-imagenet-200/imagenet.transpose.individually.augment.hdf5'#/srv/scratch/annashch/cs231n_project/imagenet.hdf5'\n",
    "data=h5py.File(path_to_data_file,'r')\n",
    "xData=data['X_valid']\n",
    "yData=np.array(data['Y_valid'])\n",
    "print(len(yData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#deeplift_output_func = theano.function([deeplift_model.get_layers()[0].get_activation_vars()],\n",
    "#                                        deeplift_model.get_layers()[-1].get_activation_vars(),\n",
    "#                                        allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "model_output_func = theano.function([keras_model.layers[0].input, K.learning_phase()], keras_model.output, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#altered_model_output_func = theano.function([altered_keras_model.layers[0].input], altered_keras_model.layers[-1].get_output(), allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 1000\n",
      "Done 2000\n",
      "Done 3000\n",
      "Done 4000\n",
      "Done 5000\n",
      "Done 6000\n",
      "Done 7000\n",
      "Done 8000\n",
      "Done 9000\n"
     ]
    }
   ],
   "source": [
    "#get indices of correct predictions\n",
    "reload(deeplift_util)\n",
    "outputs = np.array(deeplift_util.run_function_in_batches(model_output_func, input_data_list=[xData], learning_phase=0))\n",
    "#altered_outputs = np.array(deeplift_util.run_function_in_batches(altered_model_output_func, input_data_list=[xData]))\n",
    "#deeplift_outputs = deeplift_util.run_function_in_batches(deeplift_output_func, input_data_list=[xData])\n",
    "#deeplift_outputs = np.array(deeplift_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5469\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = [(i,np.max(outputs[i]))\n",
    "                           for i in xrange(len(yData))\n",
    "                           if np.argmax(yData[i]) == np.argmax(outputs[i])]\n",
    "print(len(correct_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#correct_predictions_altered = [(i,np.max(altered_outputs[i]))\n",
    "#                           for i in xrange(len(yData))\n",
    "#                           if np.argmax(yData[i]) == np.argmax(altered_outputs[i])]\n",
    "#print(len(correct_predictions_altered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rescale_func(values, squish=False):\n",
    "    values = np.sum(values,axis=0)\n",
    "    if (squish):\n",
    "        values = np.log(1+values)\n",
    "    min_val = 40\n",
    "    values = (255.0 - min_val)*(values - np.min(values))/(np.max(values)-np.min(values))  + min_val\n",
    "    return (np.transpose(np.array([values]*3), axes=(1,2,0))).astype(np.uint8)#np.sum(values,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage \n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "indices = [18, 5, 8, 24, 17]\n",
    "#indices = range(20,30)\n",
    "fig = plt.figure(figsize=(20, 4*len(indices)), facecolor='w')\n",
    "num_plots=6\n",
    "for i,idx in enumerate(indices):\n",
    "    softmax_class = np.argmax(yData[idx])\n",
    "    print(\"class:\",softmax_class)\n",
    "    (#compute gradients using the model\n",
    "    gradients,\\\n",
    "    grad_times_inp_contribs,\\\n",
    "    guided_backprop_contribs,\\\n",
    "    guided_backprop_multipliers,\\\n",
    "#    deconv_contribs,\\\n",
    "    guided_backprop_deeplift_contribs,\n",
    "    guided_backprop_deeplift_expo_upweight_contribs,\n",
    "    guided_backprop_multipliers,\n",
    "    deeplift_contribs,\n",
    "    deeplift_expo_upweight_contribs)\\\n",
    "                        = [contribs_func(task_idx=softmax_class,\n",
    "                         input_data_list=[[xData[idx]]],\n",
    "                         batch_size=10,\n",
    "                         progress_update=None)[0] for\n",
    "                           contribs_func in [\n",
    "                                             gradient_func,\n",
    "                                             grad_times_inp_func,\n",
    "                                             #deconv_multipliers_func,\n",
    "                                             guided_backprop_deeplift_contribs_func,\n",
    "                                             guided_backprop_deeplift_expo_upweight_contribs_func,\n",
    "                                             guided_backprop_multipliers_func,\n",
    "                                             #guided_backprop_multipliers_func_altered,\n",
    "                                             #gradient_func_altered,\n",
    "                                             deeplift_contribs_func,\n",
    "                                             deeplift_expo_upweight_contribs_func\n",
    "                                            ]]\n",
    "    \n",
    "    plot_print_idx = 1    \n",
    "    img_original=imread('images/val_'+str(idx)+'.JPEG').astype(np.uint8)\n",
    "    fig.subplots_adjust(wspace=0.05)\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "    #fig.subplots_adjust(right=0)\n",
    "    plt.subplot(len(indices), num_plots, i*num_plots + plot_print_idx)\n",
    "    plot_print_idx += 1\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_original)\n",
    "\n",
    "#    plt.subplot(len(indices),num_plots, i*num_plots + plot_print_idx)\n",
    "#    plot_print_idx += 1\n",
    "#    plt.title('Prepr rescale')\n",
    "#    plt.axis('off')\n",
    "    #plt.imshow((np.transpose(xData[idx], axes=(1,2,0))).astype(np.uint8))\n",
    "#    plt.imshow(rescale_func(xData[idx]))\n",
    "\n",
    "    plt.subplot(len(indices),num_plots, i*num_plots + plot_print_idx)\n",
    "    plot_print_idx += 1\n",
    "    plt.title('DeepLIFT')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(rescale_func(deeplift_contribs*(deeplift_contribs>0), squish=True))\n",
    "    \n",
    "    plt.subplot(len(indices),num_plots, i*num_plots + plot_print_idx)\n",
    "    plot_print_idx += 1\n",
    "    plt.title('DeepLIFT Exp upw')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(rescale_func(deeplift_expo_upweight_contribs*(deeplift_expo_upweight_contribs>0), squish=True))\n",
    "    \n",
    "#    plt.subplot(len(indices), num_plots, i*num_plots + plot_print_idx)\n",
    "#    plot_print_idx += 1\n",
    "#    plt.title('Guided Backprop')\n",
    "#    plt.axis('off')\n",
    "#    #plt.imshow(rescale_func(guided_backprop_multipliers*(guided_backprop_multipliers>0)))\n",
    "#    plt.imshow(rescale_func(guided_backprop_multipliers))\n",
    "\n",
    "    plt.subplot(len(indices), num_plots, i*num_plots + plot_print_idx)\n",
    "    plot_print_idx += 1\n",
    "    plt.title('Guided BP')\n",
    "    plt.axis('off')\n",
    "    #plt.imshow(rescale_func(guided_backprop_multipliers*(guided_backprop_multipliers>0)))\n",
    "    dat = guided_backprop_multipliers*xData[idx]\n",
    "    plt.imshow(rescale_func(dat*(dat > 0)))\n",
    "\n",
    "    plt.subplot(len(indices), num_plots, i*num_plots + plot_print_idx)\n",
    "    plot_print_idx += 1\n",
    "    plt.title('Guided BP DL')\n",
    "    plt.axis('off')\n",
    "    #plt.imshow(rescale_func(guided_backprop_deeplift_multipliers*(guided_backprop_deeplift_multipliers>0)))\n",
    "    plt.imshow(rescale_func(guided_backprop_deeplift_contribs*(guided_backprop_deeplift_contribs > 0) ))\n",
    "    \n",
    "    plt.subplot(len(indices), num_plots, i*num_plots + plot_print_idx)\n",
    "    plot_print_idx += 1\n",
    "    plt.title('Guided BP DL expo uw')\n",
    "    plt.axis('off')\n",
    "    #plt.imshow(rescale_func(guided_backprop_deeplift_multipliers*(guided_backprop_deeplift_multipliers>0)))\n",
    "    plt.imshow(rescale_func(guided_backprop_deeplift_expo_upweight_contribs*\n",
    "                            (guided_backprop_deeplift_expo_upweight_contribs > 0) ))\n",
    "\n",
    "    \n",
    "#    plt.subplot(len(indices), num_plots, i*num_plots + plot_print_idx)\n",
    "#    plot_print_idx += 1\n",
    "#    plt.title('Deconv')\n",
    "#    plt.axis('off')\n",
    "#    plt.imshow(rescale_func(deconv_contribs*(deconv_contribs>0)))\n",
    "    \n",
    "#    plt.subplot(len(indices), num_plots, i*num_plots + plot_print_idx)\n",
    "#    plot_print_idx += 1\n",
    "#    plt.title('Abs. gradients')\n",
    "#    plt.axis('off')\n",
    "#    plt.imshow(rescale_func(np.abs(gradients)))\n",
    "\n",
    "#    plt.subplot(len(indices), num_plots, i*num_plots + plot_print_idx)\n",
    "#    plot_print_idx += 1\n",
    "#    plt.title('Taylor')\n",
    "#    plt.axis('off')\n",
    "#    plt.imshow(rescale_func(grad_times_inp_contribs*((grad_times_inp_contribs) > 0)))\n",
    "\n",
    "    #plt.subplot(len(indices),num_plots, i*num_plots + plot_print_idx)\n",
    "    #plot_print_idx += 1\n",
    "    #plt.title('Guided Backprop Taylor')\n",
    "    #plt.axis('off')\n",
    "    #gpt = guided_backprop_contribs*xData[idx]\n",
    "    #plt.imshow(rescale_func(gpt*(gpt>0)))\n",
    "    \n",
    "    #plt.subplot(len(indices),num_plots, i*num_plots + plot_print_idx)\n",
    "    #plot_print_idx += 1\n",
    "    #plt.title('Guided Backprop DeepLIFT')\n",
    "    #plt.axis('off')\n",
    "    #gpdl = guided_backprop_deeplift_contribs*xData[idx]\n",
    "    #plt.imshow(rescale_func(gpdl*(gpdl>0)))\n",
    "    \n",
    "    #plt.subplot(len(indices),num_plots, i*num_plots + plot_print_idx)\n",
    "    #plot_print_idx += 1\n",
    "    #plt.title('difference')\n",
    "    #plt.axis('off')\n",
    "    #diff = gpdl-gpt\n",
    "    #plt.imshow(rescale_func(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_prediction_lookup = dict([x for x in correct_predictions])\n",
    "predictions_output_file = \"predictions_summary.txt\"\n",
    "fp.writeToFile(predictions_output_file, \"\\n\".join([str(i)+\"\\t\"+str(deeplift_outputs[i][np.argmax(yData[i])])\n",
    "                                                         +\"\\t\"+str(i in correct_prediction_lookup)\n",
    "                                                         +\"\\t\"+str(np.argmax(yData[i]))\n",
    "                                                         +\"\\t\"+\",\".join([str(x[0]) for x in sorted(enumerate(deeplift_outputs[i]), key=lambda x:-x[1])[:10]])\n",
    "                                                       for i in xrange(len(deeplift_outputs))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the outputs of the net on the validation set\n",
    "#reload(deepLIFTutils)\n",
    "#print(np.shape(data))\n",
    "#import theano\n",
    "#import deeplift_util\n",
    "#\n",
    "#keras_output_func = theano.function([keras_model.layers[0].input],\n",
    "#                                     keras_model.layers[-1].get_output(train=False),\n",
    "#                                     allow_input_downcast=True)\n",
    "#keras_outputs = deeplift_util.run_function_in_batches(keras_output_func, input_data_list=[data])\n",
    "#keras_outputs=np.array(keras_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#deeplift_output_func = theano.function([deeplift_model.get_layers()[0].get_activation_vars()],\n",
    "#                                        deeplift_model.get_layers()[-1].get_activation_vars(),\n",
    "#                                        allow_input_downcast=True)\n",
    "#deeplift_outputs = deeplift_util.run_function_in_batches(deeplift_output_func, input_data_list=[data])\n",
    "#deeplift_outputs = np.array(deeplift_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.sum(np.abs(keras_outputs-deeplift_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rescale_func_for_image(values):\n",
    "    min_val = 0\n",
    "    values = (255.0 - min_val)*(values - np.min(values))/(np.max(values)-np.min(values))  + min_val\n",
    "    return np.transpose(np.array([values]*3), axes=(1,2,0))#np.sum(values,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "def save_image(values, output_dir, suffix, idx):\n",
    "    values = rescale_func(values).astype(np.uint8)\n",
    "    name = output_dir+\"/val_\"+str(idx)+\"_\"+suffix+\".PNG\"\n",
    "    scipy.misc.imsave(name, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveSequentialToHDF5\n",
    "    import h5py;                                                                \n",
    "    f=h5py.File(options.saveToHDF5,'w')                                         \n",
    "    dsetNames=['train','valid','test','eval']                                   \n",
    "    dsetVals=[trainData,validData,testData,evalData]                            \n",
    "    for i in range(len(dsetNames)):                                             \n",
    "        if dsetVals[i]==None:                                                   \n",
    "            continue #case when eval set is not used                            \n",
    "        dsetName=dsetNames[i]                                                   \n",
    "        dsetVal=dsetVals[i]                                                     \n",
    "        dset_Ids=f.create_dataset(dsetName+\"Id\",data=dsetVal.ids)               \n",
    "        dset_X=f.create_dataset(dsetName+\"X\",data=dsetVal.X)                    \n",
    "        dset_Y=f.create_dataset(dsetName+\"Y\",data=dsetVal.Y)                    \n",
    "        dset_LabelNames=f.create_dataset(dsetName+\"LabelNames\",data=dsetVal.labelNames)\n",
    "        if dsetVal.featureNames!=None:                                          \n",
    "            dset_FeatureNames=f.create_dataset(dsetName+\"FeatureNames\",data=dsetVal.featureNames)\n",
    "        if dsetVal.weights!=None:                                               \n",
    "            dset_Weights=f.create_dataset(dsetName+\"Weights\",data=dsetVal.weights)\n",
    "    f.flush()                                                                   \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flush_class(class_to_datapoints, class_to_datapoint_indices, the_class):\n",
    "    datapoints = class_to_datapoints[the_class]\n",
    "    indices = class_to_datapoint_indices[the_class]\n",
    "    class_to_datapoints[the_class] = []\n",
    "    class_to_datapoint_indices[the_class] = []\n",
    "    deeplift_contribs = target_contribs_func(task_idx=the_class,\n",
    "                                             input_data_list=[datapoints],\n",
    "                                             batch_size=10,\n",
    "                                             progress_update=None)\n",
    "    gradients, grad_times_inp_contribs, deeplift_contribs =\\\n",
    "                                                [contribs_func(task_idx=the_class,\n",
    "                                                         input_data_list=[datapoints],\n",
    "                                                         batch_size=10,\n",
    "                                                         progress_update=None) for\n",
    "                                                           contribs_func in [gradient_func,\n",
    "                                                                             grad_times_inp_func,\n",
    "                                                                             deeplift_contribs_func]]\n",
    "    for j in xrange(len(gradients)):\n",
    "        simonyan = np.abs(gradients[j])\n",
    "        simonyan_blackwhite = np.linalg.norm(simonyan, axis=0)\n",
    "        \n",
    "        grad_x_inp = (gradients[j]*datapoints[j])*(gradients[j]*datapoints[j])\n",
    "        grad_x_inp_blackwhite = np.sum(grad_x_inp > 0, axis=0)\n",
    "        deeplift_contr = deeplift_contribs[j]\n",
    "        deeplift_contribs_blackwhite = np.sum(deeplift_contr > 0, axis=0)\n",
    "        \n",
    "        for (image, image_name) in [(simonyan_blackwhite, \"simonyan\"),\n",
    "                                    (grad_x_inp_blackwhite, \"grad-x-inp\"),\n",
    "                                    (deeplift_contribs_blackwhite, \"liftpad\")]:\n",
    "            save_image(image, output_dir, image_name, indices[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "read_data_batch_size = 100\n",
    "class_flush_threshold = 10\n",
    "output_dir=\"saliency_maps\"\n",
    "num_classes=200\n",
    "\n",
    "class_to_datapoints = dict([(x,[]) for x in xrange(num_classes)])\n",
    "class_to_datapoint_indices = dict([(x,[]) for x in xrange(num_classes)])\n",
    "while i < len(xData):\n",
    "    if (i%1000 == 0):\n",
    "        print(\"Done \",i)\n",
    "    xDataInMem = np.array(xData[i:i+read_data_batch_size])\n",
    "    for j in xrange(len(xDataInMem)):\n",
    "        the_class = np.argmax(yData[i+j])\n",
    "        class_to_datapoints[the_class].append(xDataInMem[j])\n",
    "        class_to_datapoint_indices[the_class].append(i+j)\n",
    "        if (len(class_to_datapoints[the_class]) > class_flush_threshold):\n",
    "            flush_class(class_to_datapoints, class_to_datapoint_indices, the_class)\n",
    "    i += read_data_batch_size\n",
    "\n",
    "for the_class in xrange(num_classes):\n",
    "    flush_class(class_to_datapoints, class_to_datapoint_indices, the_class)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
