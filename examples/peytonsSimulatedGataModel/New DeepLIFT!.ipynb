{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General import statements. REMEMBER, DEEPLIFT_DIR needs to point to the deeplift directory WITHIN the deeplift repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 750M (CNMeM is disabled, CuDNN not available)\n",
      "/Users/avantishrikumar/anaconda/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division;\n",
    "from __future__ import print_function;\n",
    "from __future__ import absolute_import;\n",
    "import sys, os;\n",
    "from collections import OrderedDict, namedtuple;\n",
    "import numpy as np;\n",
    "\n",
    "#import deepLIFT stuff\n",
    "scriptsDir = os.environ.get(\"DEEPLIFT_DIR\");\n",
    "if (scriptsDir is None):\n",
    "    raise Exception(\"Please set environment variable DEEPLIFT_DIR to point to the deeplift code (WITHIN the deeplift repo)\");\n",
    "sys.path.insert(0,scriptsDir);\n",
    "#Make sure the directory is set to import the lab's version of keras\n",
    "scriptsDir = os.environ.get(\"KERAS_DIR\");\n",
    "if (scriptsDir is None):\n",
    "    raise Exception(\"Please set environment variable KERAS_DIR\");\n",
    "sys.path.insert(0,scriptsDir)\n",
    "\n",
    "import keras_conversion as kc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#Load the keras model, make sure you normalise the weights\n",
    "#of the first convolutional layer to be mean-centered at each position.\n",
    "model_weights = \"apr11_deltaDeepLift_3task_2motif_deptask2_samplepwm_numSeq_20000_peakSize_200_DNNSimModel_20filt_15bp_plst50_200fc_do_epoch_42_modelWeights.h5\"\n",
    "model_yaml = \"apr11_deltaDeepLift_3task_2motif_deptask2_samplepwm_numSeq_20000_peakSize_200_DNNSimModel_20filt_15bp_plst50_200fc_do_epoch_42_modelYaml.yaml\"\n",
    "reload(kc)\n",
    "keras_model = kc.load_keras_model(model_weights, model_yaml, normalise_conv_for_one_hot_encoded_input=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000 lines of apr10_deltaDeepLift_3task_2motif_deptask2_numSeq_20000_peakSize_200_TAL1_known1_GATA_known4_numSeq_20000_peakSize_200_freqMoMean_2_w_SPI1_known4_AP1_disc3_joint.fa.gz\n",
      "Processed 20000 lines of apr10_deltaDeepLift_3task_2motif_deptask2_numSeq_20000_peakSize_200_TAL1_known1_GATA_known4_numSeq_20000_peakSize_200_freqMoMean_2_w_SPI1_known4_AP1_disc3_joint.fa.gz\n",
      "('WARNING.', 'cls2_6001', 'was not found in train/test/valid splits')\n",
      "This is the only time such a warning will be printed. Remaining such ids will be silently ignored\n",
      "Processed 30000 lines of apr10_deltaDeepLift_3task_2motif_deptask2_numSeq_20000_peakSize_200_TAL1_known1_GATA_known4_numSeq_20000_peakSize_200_freqMoMean_2_w_SPI1_known4_AP1_disc3_joint.fa.gz\n",
      "Processed 40000 lines of apr10_deltaDeepLift_3task_2motif_deptask2_numSeq_20000_peakSize_200_TAL1_known1_GATA_known4_numSeq_20000_peakSize_200_freqMoMean_2_w_SPI1_known4_AP1_disc3_joint.fa.gz\n",
      "Processed 50000 lines of apr10_deltaDeepLift_3task_2motif_deptask2_numSeq_20000_peakSize_200_TAL1_known1_GATA_known4_numSeq_20000_peakSize_200_freqMoMean_2_w_SPI1_known4_AP1_disc3_joint.fa.gz\n",
      "Processed 60000 lines of apr10_deltaDeepLift_3task_2motif_deptask2_numSeq_20000_peakSize_200_TAL1_known1_GATA_known4_numSeq_20000_peakSize_200_freqMoMean_2_w_SPI1_known4_AP1_disc3_joint.fa.gz\n",
      "(2, 'rows skipped from', 'apr10_deltaDeepLift_3task_2motif_deptask2_numSeq_20000_peakSize_200_TAL1_known1_GATA_known4_numSeq_20000_peakSize_200_freqMoMean_2_w_SPI1_known4_AP1_disc3_joint.fa.gz')\n",
      "Done loading in fastas\n",
      "Returning desired dict\n",
      "Making numpy arrays out of the loaded files\n",
      "('train', 'shape', (24002, 1, 4, 200))\n",
      "('train', 'shape', (24002, 3))\n",
      "('test', 'shape', (18000, 1, 4, 200))\n",
      "('test', 'shape', (18000, 3))\n",
      "('valid', 'shape', (18000, 1, 4, 200))\n",
      "('valid', 'shape', (18000, 3))\n"
     ]
    }
   ],
   "source": [
    "scriptsDir = os.environ.get(\"UTIL_SCRIPTS_DIR\");\n",
    "if (scriptsDir is None):\n",
    "    raise Exception(\"Please set environment variable UTIL_SCRIPTS_DIR to point to the deeplift code\");\n",
    "sys.path.insert(0,scriptsDir);\n",
    "from importDataPackage import importData\n",
    "reload(importData)\n",
    "trainData, validData, testData = importData.loadTrainTestValidFromYaml(\"yaml/features.yaml\",\"yaml/labels.yaml\", \"yaml/splits.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = trainData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the keras sequential model into a deeplift sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import blobs\n",
    "reload(blobs)\n",
    "deeplift_model = kc.convert_sequential_model(keras_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the functions to compute the contributions and multipliers - the multipliers are analogous to the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_contribs_func = deeplift_model.get_target_contribs_func(input_layer_idx=0)\n",
    "target_multipliers_func = deeplift_model.get_target_multipliers_func(input_layer_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the contributions for all 3 tasks and the multipliers for the third task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done"
     ]
    }
   ],
   "source": [
    "contribs_datas = [np.array(target_contribs_func(task_idx=i, input_data_list=[data.X], batch_size=10, progress_update=10000))\n",
    "                  for i in [0,1,2]]\n",
    "\n",
    "multipliers_data_task2 = np.array(target_multipliers_func(task_idx=2, input_data_list=[data.X], batch_size=10, progress_update=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot away! This relies on importing some plotting functions from the old DeepLIFT code base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scriptsDir = os.environ.get(\"ENHANCER_SCRIPTS_DIR\");\n",
    "if (scriptsDir is None):\n",
    "    raise Exception(\"Please set environment variable ENHANCER_SCRIPTS_DIR to point to the enhancer_prediction_code repo\");\n",
    "sys.path.insert(0,scriptsDir+\"/featureSelector/deepLIFFT\");\n",
    "from deepLIFTutils import makePngOfSequenceDeepLIFTScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = 19643 #coordinates of the GATA are 123-136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the contribution scores for the three tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for task in [0,1,2]:\n",
    "    makePngOfSequenceDeepLIFTScores(contribs_datas[task][idx]\n",
    "                                    , pngName=\"task\"+str(task)+\"_sequenceDLscores_weirdOne_\"+str(idx)+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the multipliers for the third task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "makePngOfSequenceDeepLIFTScores(multipliers_data_task2[idx]\n",
    "                                    , pngName=\"task\"+str(task)+\"_multipliers_weirdOne_\"+str(idx)+\".png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
