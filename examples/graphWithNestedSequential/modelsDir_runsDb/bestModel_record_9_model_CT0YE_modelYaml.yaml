input_config:
- dtype: float
  input_shape: !!python/tuple [1, 4, 1000]
  name: inputMode1
input_order: [inputMode1]
loss: {EE_L3: categorical_crossentropy, EE_YA: categorical_crossentropy, L3_YA: categorical_crossentropy,
  binary: weighted_binary_crossentropy}
name: Graph
node_config:
- concat_axis: -1
  create_output: false
  dot_axes: -1
  input: inputMode1
  inputs: &id001 []
  merge_mode: concat
  name: sequentialCore
- concat_axis: -1
  create_output: false
  dot_axes: -1
  input: sequentialCore
  inputs: *id001
  merge_mode: concat
  name: preOutput-EE_L3
- concat_axis: -1
  create_output: false
  dot_axes: -1
  input: sequentialCore
  inputs: *id001
  merge_mode: concat
  name: preOutput-EE_YA
- concat_axis: -1
  create_output: false
  dot_axes: -1
  input: sequentialCore
  inputs: *id001
  merge_mode: concat
  name: preOutput-L3_YA
- concat_axis: -1
  create_output: false
  dot_axes: -1
  input: sequentialCore
  inputs: *id001
  merge_mode: concat
  name: preOutput-binary
nodes:
  preOutput-EE_L3:
    layers:
    - W_constraint: null
      W_learning_rate_multiplier: 1.0
      W_regularizer: null
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_learning_rate_multiplier: 1.0
      b_regularizer: null
      cache_enabled: true
      custom_name: dense
      init: glorot_uniform
      input_dim: null
      input_shape: !!python/tuple [1000]
      name: Dense
      output_dim: 3
      trainable: true
    - {activation: softmax, cache_enabled: true, custom_name: activation, name: Activation,
      trainable: true}
    name: Sequential
  preOutput-EE_YA:
    layers:
    - W_constraint: null
      W_learning_rate_multiplier: 1.0
      W_regularizer: null
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_learning_rate_multiplier: 1.0
      b_regularizer: null
      cache_enabled: true
      custom_name: dense
      init: glorot_uniform
      input_dim: null
      input_shape: !!python/tuple [1000]
      name: Dense
      output_dim: 3
      trainable: true
    - {activation: softmax, cache_enabled: true, custom_name: activation, name: Activation,
      trainable: true}
    name: Sequential
  preOutput-L3_YA:
    layers:
    - W_constraint: null
      W_learning_rate_multiplier: 1.0
      W_regularizer: null
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_learning_rate_multiplier: 1.0
      b_regularizer: null
      cache_enabled: true
      custom_name: dense
      init: glorot_uniform
      input_dim: null
      input_shape: !!python/tuple [1000]
      name: Dense
      output_dim: 3
      trainable: true
    - {activation: softmax, cache_enabled: true, custom_name: activation, name: Activation,
      trainable: true}
    name: Sequential
  preOutput-binary:
    layers:
    - W_constraint: null
      W_learning_rate_multiplier: 1.0
      W_regularizer: null
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_learning_rate_multiplier: 1.0
      b_regularizer: null
      cache_enabled: true
      custom_name: dense
      init: glorot_uniform
      input_dim: null
      input_shape: !!python/tuple [1000]
      name: Dense
      output_dim: 3
      trainable: true
    - {activation: sigmoid, cache_enabled: true, custom_name: activation, name: Activation,
      trainable: true}
    name: Sequential
  sequentialCore:
    layers:
    - W_constraint: null
      W_learning_rate_multiplier: 1.0
      W_regularizer: null
      activation: linear
      activity_regularizer: {l1: 1.0e-07, l2: 0, name: ActivityRegularizer}
      b_constraint: null
      b_learning_rate_multiplier: 1.0
      b_regularizer: null
      border_mode: valid
      cache_enabled: true
      custom_name: convolution2d
      dim_ordering: th
      init: glorot_uniform
      input_shape: !!python/tuple [1, 4, 1000]
      name: Convolution2D
      nb_col: 4
      nb_filter: 250
      nb_row: 4
      subsample: &id002 !!python/tuple [1, 1]
      trainable: true
    - {activation: relu, cache_enabled: true, custom_name: activation, name: Activation,
      trainable: true}
    - border_mode: valid
      cache_enabled: true
      custom_name: maxpooling2d
      dim_ordering: th
      name: MaxPooling2D
      pool_size: !!python/tuple [1, 3]
      strides: !!python/tuple [1, 3]
      trainable: true
    - W_constraint: {axis: 0, m: 7.0, name: MaxNorm}
      W_learning_rate_multiplier: 1.0
      W_regularizer: null
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_learning_rate_multiplier: 1.0
      b_regularizer: null
      border_mode: valid
      cache_enabled: true
      custom_name: convolution2d
      dim_ordering: th
      init: glorot_uniform
      input_shape: !!python/tuple [250, 1, 332]
      name: Convolution2D
      nb_col: 4
      nb_filter: 500
      nb_row: 1
      subsample: *id002
      trainable: true
    - {activation: relu, cache_enabled: true, custom_name: activation, name: Activation,
      trainable: true}
    - border_mode: valid
      cache_enabled: true
      custom_name: maxpooling2d
      dim_ordering: th
      name: MaxPooling2D
      pool_size: !!python/tuple [1, 7]
      strides: !!python/tuple [1, 7]
      trainable: true
    - W_constraint: {axis: 0, m: 7.0, name: MaxNorm}
      W_learning_rate_multiplier: 1.0
      W_regularizer: null
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_learning_rate_multiplier: 1.0
      b_regularizer: null
      border_mode: valid
      cache_enabled: true
      custom_name: convolution2d
      dim_ordering: th
      init: glorot_uniform
      input_shape: !!python/tuple [500, 1, 47]
      name: Convolution2D
      nb_col: 7
      nb_filter: 250
      nb_row: 1
      subsample: *id002
      trainable: true
    - {activation: relu, cache_enabled: true, custom_name: activation, name: Activation,
      trainable: true}
    - border_mode: valid
      cache_enabled: true
      custom_name: maxpooling2d
      dim_ordering: th
      name: MaxPooling2D
      pool_size: !!python/tuple [1, 7]
      strides: !!python/tuple [1, 7]
      trainable: true
    - {cache_enabled: true, custom_name: flatten, name: Flatten, trainable: true}
    - W_constraint: {axis: 0, m: 7.0, name: MaxNorm}
      W_learning_rate_multiplier: 1.0
      W_regularizer: null
      activation: linear
      activity_regularizer: {l1: 1.0e-07, l2: 0, name: ActivityRegularizer}
      b_constraint: null
      b_learning_rate_multiplier: 1.0
      b_regularizer: null
      cache_enabled: true
      custom_name: dense
      init: glorot_uniform
      input_dim: null
      input_shape: !!python/tuple [1000]
      name: Dense
      output_dim: 1000
      trainable: true
    - {cache_enabled: true, custom_name: prelu, init: zero, name: PReLU, trainable: true}
    - {cache_enabled: true, custom_name: dropout, name: Dropout, p: 0.3, trainable: true}
    - W_constraint: {axis: 0, m: 7.0, name: MaxNorm}
      W_learning_rate_multiplier: 1.0
      W_regularizer: null
      activation: linear
      activity_regularizer: {l1: 1.0e-07, l2: 0, name: ActivityRegularizer}
      b_constraint: null
      b_learning_rate_multiplier: 1.0
      b_regularizer: null
      cache_enabled: true
      custom_name: dense
      init: glorot_uniform
      input_dim: null
      input_shape: !!python/tuple [1000]
      name: Dense
      output_dim: 1000
      trainable: true
    - {cache_enabled: true, custom_name: prelu, init: zero, name: PReLU, trainable: true}
    - {cache_enabled: true, custom_name: dropout, name: Dropout, p: 0.3, trainable: true}
    name: Sequential
optimizer: {beta_1: 0.8999999761581421, beta_2: 0.9990000128746033, epsilon: 1.0e-08,
  lr: 0.0010000000474974513, name: Adam}
output_config:
- concat_axis: -1
  dot_axes: -1
  input: preOutput-EE_L3
  inputs: &id003 []
  merge_mode: concat
  name: EE_L3
- concat_axis: -1
  dot_axes: -1
  input: preOutput-EE_YA
  inputs: *id003
  merge_mode: concat
  name: EE_YA
- concat_axis: -1
  dot_axes: -1
  input: preOutput-L3_YA
  inputs: *id003
  merge_mode: concat
  name: L3_YA
- concat_axis: -1
  dot_axes: -1
  input: preOutput-binary
  inputs: *id003
  merge_mode: concat
  name: binary
output_order: [EE_L3, EE_YA, L3_YA, binary]
