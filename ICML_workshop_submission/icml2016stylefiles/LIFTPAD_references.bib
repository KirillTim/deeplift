% Generated by Paperpile. Check out http://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.

@INCOLLECTION{Zeiler2014-sk,
  title     = "Visualizing and understanding convolutional networks",
  booktitle = "Computer {vision--ECCV} 2014",
  author    = "Zeiler, Matthew D and Fergus, Rob",
  publisher = "Springer",
  pages     = "818--833",
  year      =  2014
}

@ARTICLE{Hochreiter1997-yn,
  title       = "Long short-term memory",
  author      = "Hochreiter, S and Schmidhuber, J",
  affiliation = "Fakult{\"{a}}t f{\"{u}}r Informatik, Technische
                 Universit{\"{a}}t M{\"{u}}nchen, Germany.",
  abstract    = "Learning to store information over extended time intervals by
                 recurrent backpropagation takes a very long time, mostly
                 because of insufficient, decaying error backflow. We briefly
                 review Hochreiter's (1991) analysis of this problem, then
                 address it by introducing a novel, efficient, gradient-based
                 method called long short-term memory (LSTM). Truncating the
                 gradient where this does not do harm, LSTM can learn to bridge
                 minimal time lags in excess of 1000 discrete-time steps by
                 enforcing constant error flow through constant error carousels
                 within special units. Multiplicative gate units learn to open
                 and close access to the constant error flow. LSTM is local in
                 space and time; its computational complexity per time step and
                 weight is O(1). Our experiments with artificial data involve
                 local, distributed, real-valued, and noisy pattern
                 representations. In comparisons with real-time recurrent
                 learning, back propagation through time, recurrent cascade
                 correlation, Elman nets, and neural sequence chunking, LSTM
                 leads to many more successful runs, and learns much faster.
                 LSTM also solves complex, artificial long-time-lag tasks that
                 have never been solved by previous recurrent network
                 algorithms.",
  journal     = "Neural Comput.",
  volume      =  9,
  number      =  8,
  pages       = "1735--1780",
  month       =  "15~" # nov,
  year        =  1997
}

@MISC{Chollet2015-ya,
  title  = "Keras",
  author = "Chollet, Franois",
  year   =  2015
}

@ARTICLE{Simonyan2013-hk,
  title         = "Deep Inside Convolutional Networks: Visualising Image
                   Classification Models and Saliency Maps",
  author        = "Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew",
  abstract      = "This paper addresses the visualisation of image
                   classification models, learnt using deep Convolutional
                   Networks (ConvNets). We consider two visualisation
                   techniques, based on computing the gradient of the class
                   score with respect to the input image. The first one
                   generates an image, which maximises the class score [Erhan
                   et al., 2009], thus visualising the notion of the class,
                   captured by a ConvNet. The second technique computes a class
                   saliency map, specific to a given image and class. We show
                   that such maps can be employed for weakly supervised object
                   segmentation using classification ConvNets. Finally, we
                   establish the connection between the gradient-based ConvNet
                   visualisation methods and deconvolutional networks [Zeiler
                   et al., 2013].",
  month         =  "20~" # dec,
  year          =  2013,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  eprint        = "1312.6034"
}

@INPROCEEDINGS{Long2015-kw,
  title     = "Fully convolutional networks for semantic segmentation",
  booktitle = "Proceedings of the {IEEE} Conference on Computer Vision and
               Pattern Recognition",
  author    = "Long, Jonathan and Shelhamer, Evan and Darrell, Trevor",
  pages     = "3431--3440",
  year      =  2015
}

@ARTICLE{Springenberg2014-gg,
  title         = "Striving for Simplicity: The All Convolutional Net",
  author        = "Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox,
                   Thomas and Riedmiller, Martin",
  abstract      = "Most modern convolutional neural networks (CNNs) used for
                   object recognition are built using the same principles:
                   Alternating convolution and max-pooling layers followed by a
                   small number of fully connected layers. We re-evaluate the
                   state of the art for object recognition from small images
                   with convolutional networks, questioning the necessity of
                   different components in the pipeline. We find that
                   max-pooling can simply be replaced by a convolutional layer
                   with increased stride without loss in accuracy on several
                   image recognition benchmarks. Following this finding -- and
                   building on other recent work for finding simple network
                   structures -- we propose a new architecture that consists
                   solely of convolutional layers and yields competitive or
                   state of the art performance on several object recognition
                   datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the
                   network we introduce a new variant of the ``deconvolution
                   approach'' for visualizing features learned by CNNs, which
                   can be applied to a broader range of network structures than
                   existing approaches.",
  month         =  "21~" # dec,
  year          =  2014,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "1412.6806"
}

@ARTICLE{Chung2014-uj,
  title         = "Empirical Evaluation of Gated Recurrent Neural Networks on
                   Sequence Modeling",
  author        = "Chung, Junyoung and Gulcehre, Caglar and Cho, Kyunghyun and
                   Bengio, Yoshua",
  abstract      = "In this paper we compare different types of recurrent units
                   in recurrent neural networks (RNNs). Especially, we focus on
                   more sophisticated units that implement a gating mechanism,
                   such as a long short-term memory (LSTM) unit and a recently
                   proposed gated recurrent unit (GRU). We evaluate these
                   recurrent units on the tasks of polyphonic music modeling
                   and speech signal modeling. Our experiments revealed that
                   these advanced recurrent units are indeed better than more
                   traditional recurrent units such as tanh units. Also, we
                   found GRU to be comparable to LSTM.",
  month         =  "11~" # dec,
  year          =  2014,
  archivePrefix = "arXiv",
  primaryClass  = "cs.NE",
  eprint        = "1412.3555"
}

