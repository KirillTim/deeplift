%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% ICML 2015 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use the following line _only_ if you're still using LaTeX 2.09.
%\documentstyle[icml2015,epsf,natbib]{article}
% If you rely on Latex2e packages, like most modern people use this:
\documentclass{article}

% use Times
\usepackage{times}
% For figures
\usepackage{graphicx} % more modern
%\usepackage{epsfig} % less modern
\usepackage{subfigure} 

% For citations
\usepackage{natbib}

% For algorithms
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}

% As of 2011, we use the hyperref package to produce hyperlinks in the
% resulting PDF.  If this breaks your system, please commend out the
% following usepackage line and replace \usepackage{icml2015} with
% \usepackage[nohyperref]{icml2015} above.
\usepackage{hyperref}

% Packages hyperref and algorithmic misbehave sometimes.  We can fix
% this with the following command.
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Employ the following version of the ``usepackage'' statement for
% submitting the draft version of the paper for review.  This will set
% the note in the first column to ``Under review.  Do not distribute.''
\usepackage{icml2015} 

% Employ this version of the ``usepackage'' statement after the paper has
% been accepted, when creating the final version.  This will set the
% note in the first column to ``Proceedings of the...''
%\usepackage[accepted]{icml2015}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Submission and Formatting Instructions for ICML 2015}

\begin{document} 

\twocolumn[
\icmltitle{LIFFTing the Top off the Black Box: \\ 
           Feature Selection for Neural Networks in Biology}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2015
% package.
\icmlauthor{Your Name}{email@yourdomain.edu}
\icmladdress{Your Fantastic Institute,
            314159 Pi St., Palo Alto, CA 94306 USA}
\icmlauthor{Your CoAuthor's Name}{email@coauthordomain.edu}
\icmladdress{Their Fantastic Institute,
            27182 Exp St., Toronto, ON M6H 2T1 CANADA}

% You may provide any keywords that you 
% find helpful for describing your paper; these are used to populate 
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{DeepLIFT, deep learning, interpretability, interpretable, neural networks, importance, feature importance, ICML}

\vskip 0.3in
]

\begin{abstract} 
A common criticism of neural networks is their lack of interpretability or ``black box" nature. This is a major barrier to adoption in application domains such as biology, where interpretability is important. Here we present DeepLIFT (Deep Linear Importance Feature Tracker), an intuitive and effective method for scoring the contributions of inputs to the output of a neural network. DeepLIFT compares the activation of each neuron to its `default activation', and assigns a contribution score to each of the neuron's inputs proportionally to how the inputs differ from their own `default activations'. We apply DeepLIFT to models trained on natural images as well as models trained on genomic sequences. We show that DeepLIFT correctly identifies important features in both cases and has significant advantages over gradient-based methods.
\end{abstract} 

\section{Introduction}
\label{introduction}

As neural networks become increasingly popular, their reputation as a ``black box" presents a barrier to adoption in fields were interpretability is paramount. Understanding the features that lead to a particular output builds trust with users and can lead to novel scientific discoveries. A common approach is to leverage the gradients of a particular output with respect to the individual inputs (Simonyan et al. - cite) - however, approaches are limited because commonly used activation functions such as Rectified Linear Units (ReLUs) have a gradient of zero when they are not firing, yet a ReLU that does not fire can still carry information - particularly if the associated bias is positive (which means that in the absence of any input, the ReLU does fire). Similarly, sigmoid or tanh activations are popular choices for the activation functions of gates in memory units of recurrent neural networks such as GRUs and LSTMs (cite), but these activations have a near-zero gradient at high or low inputs even though such inputs can be very significant.

In this paper, we present a general method for assigning feature importance which focuses on the difference between a neuron's activation and its `default' activation, where the default activation is the activation that the neuron has when the network is provided a `default input'. The default input is defined on a domain-specific basis according to what is appropriate for the task at hand. This circumvents the aforementioned limitation of gradient-based approaches because, rather than relying on the local gradient at the point of activation, the activation is simply compared to its default value. In the case of a ReLU which fires when provided the default input (as is typically the case for ReLUs that have a positive bias), our method assigns a negative `difference from default' when the ReLU does not fire. Similarly, in the case of a sigmoidal unit which has an output of $0.5$ when provided the default input, our method would assign a positive `difference from default' when the sigmoidal unit has an output near $1$, even though the gradient at that output is negligible.

\section{DeepLIFT Method}
\label{DeepLIFT}

We define the contributions of every neuron $x$ to some downstream neuron $y$. We denote the contribution of $x$ to $y$ as $C_{xy}$. Let the activation of a neuron $n$ be denoted as $A_n$. Further, let the \emph{default} activation of neuron $n$ be denoted $A_n^0$, and let the $A_n - A_n^0$ be denoted as $\delta_n$. We define our contributions $C_{xy}$ to satisfy the following properties.

\subsection{Summation to $\delta$}

For any set of neurons $S$ whose activations are minimally sufficient to compute the activation of $y$ (that is, if we know the activations of $S$, we can compute the activation of $y$, and there is no set $S' \subset S$ such that $S'$ is sufficient to compute the activation of $y$ - in layman's terms, $S$ is a full set of non-redundant inputs to $y$), the following property holds:
\begin{equation}
\sum_{s \in S} C_{sy} = \delta_y
\end{equation}
That is, the sum over all the contributions of neurons in $S$ equals the difference-from-default of $y$.

\subsection{Linear composition}

Let $O_x$ represent the output neurons of $x$. The following property holds:\\
\begin{equation}
C_{xy} = \sum_{o \in O_x} \frac{C_{xo}}{\delta_o}C_{oy}
\end{equation}
In layman's terms, each neuron `inherits' a contribution through its outputs in proportion to how much that neuron contributes to the difference-from-default of the output.

\subsection{Backpropagation Rules}

We show that the contributions as defined above can be computed using the following rules (which can be implemented to run on a GPU). The computation is reminiscent of backpropagation, as equation $2$ allows contribution scores to be computed efficiently via dynamic programming. To avoid issues of numerical stability when $\delta_n$ for a particular neuron is small, rather than computing the contribution scores explicitly, we instead compute \emph{multipliers} $m_{xy}$ that satisfy the following condition:
\begin{equation}
m_{xy} \delta_x = C_{xy}
\end{equation} 
In the equations below, $I_y$ denotes the set of inputs of $y$, and $t$ represents the target neuron that we intent to compute the contributions to.

\subsubsection{Linearity}
Let
\begin{equation}
A_y = \left(\sum_{x \in I_y} w_{xy} A_x\right) + b  
\end{equation}
Then
\begin{equation}
\begin{aligned}
m_{xy} &= w_{xy}
m_{xt} &= w_{xy} m_{yt}
\end{aligned}
\end{equation}

{\bf Proof of summation to $\delta$}

We show that
\begin{equation}
\sum_{x \in I_y} m_{xt} \delta_x = m_{yt} \delta_y
\end{equation}
Using the fact that $A_n = A_n^0 + \delta_n$, we have:
\begin{equation}
\begin{aligned}
(A_y^0 + \delta_y) &= \left(\sum_{x \in I_y} w_{xy} (A_x^0 + \delta_x) \right) + b \\
(A_y^0 + \delta_y) &= \left(\sum_{x \in I_y} w_{xy} A_x^0 \right) + b + \sum_{x \in I_y} w_{xy} \delta_x
\end{aligned}
\end{equation} 
We also note that the default activation $A_y^0$ can be found as follows:
\begin{equation}
A_y^0 = \left(\sum_{x \in I_y} w_{xy} A_x^0 \right) + b
\end{equation}
Thus, canceling out $A_y^0$ yields:
\begin{equation}
\begin{aligned}
\delta_y &= \sum_{x \in I_y} w_{xy} \delta_x\\
m_{yt} \delta_y &= \sum_{x \in I_y} m_{yt} w_{xy} \delta_x\\
m_{yt} \delta_y &= \sum_{x \in I_y} m_{xt} \delta_x 
\end{aligned}
\end{equation} 



\end{document} 

% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was
% created by Lise Getoor and Tobias Scheffer, it was slightly modified  
% from the 2010 version by Thorsten Joachims & Johannes Fuernkranz, 
% slightly modified from the 2009 version by Kiri Wagstaff and 
% Sam Roweis's 2008 version, which is slightly modified from 
% Prasad Tadepalli's 2007 version which is a lightly 
% changed version of the previous year's version by Andrew Moore, 
% which was in turn edited from those of Kristian Kersting and 
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.  


